** Physics Engine (refined) 
A physics engine allows us to model physical interaction. We may chose to abide by or manipulate the terrestrial laws of gravity. Light, rain, and the relationship between objects are all programmable in a physics engine. 

With a virtual environment that includes human movement, we must program their virtual characteristics. When building an environment of virtual football players, for example, we must assign certain properties to each player. X player weighs y pounds and has the ability to jump z height. 

For many virtual creators, it's important that the constructed environment abides by basic real-world physical parameters. For example, when the user makes contact with a wall in a virtual space, the VR builder can work with a physics engine to cause the user's movement to be interrupted by this wall, rather than passing directly through it. 

"Unity" supports the most dynamic physics engine.

** Physics Engine (raw)  

- Python we can script blender 

- physics engine: model some sort of physical interaction 
 + can modify the physics so the world does not have to abide by laws of physics: light, rain, etc. 
 + movement and logic added to their models. 

- Difference between blender and game engine: model 3D volumes, give them skeleton. Port them into game enigne. This allows you to put physics on these volumes. 
 + Football player volume: this volume has x weight and it is allowed to jump y height. 
 + Blender does not have this sense of weight or colision 
 + you should not be able to go through the walls 
 + Camera should recognize where the wall is and you can't go through the wall 

PHysics engine allows you to create parameters. 

- Wall example defiens physicsl parameters of space
- phsical parameters of a moving objects 
 + gravity is taken into account 
 + as a VR programmer you say this object weights X and has Y ability (classical physics 

- physics engine to define gravity and mass, you can allow for collisions and gravitational pull 

 + momentum is also defined 
 + magnetism needs to be added to the objects 
 + gravity 

physical laws relative to electromagnetism: electricity

relativistic mechanics: gravity

classical mechanics
 + mechanics: related to newton's laws: 1) action/reaction,  

...
** Python (refined) 
Python is a succinct, object oriented programming language. It's scripting capabilities allow programmers to design visual assets by writing lines of code into a game engine like Blender. Not only can we generate shapes with python but we can also manipulate, scale, and put them into motion. 

Python is also used for networking the server that will handle the database for your VR experience.

This is the default language of the machine learning world. While machine learning toolboxes are written in C++ (for performance benefits), we often use python as the intermediary tool to access these stores. Combining these languages for this combines the succinctness of python with the performance of C++ For this purpose, it functions as a librarian who retrieves a book for us from the stacks.

Python is not so applicable to direct vr creation but it enables functionalities that VR wants in order to reach maximum performance  

** Python (Raw) 
 - Python is a succinct language. 
- Object oriented programming 
- Not used in VR bcause it's not performant enough 
- Used heavily in 
 - 1) 3D modelers: Blender allows you to script using python 
 - 2) Allows you to code a shape by coding with python on Blender 
 - 3) Generate the shape
 - 4) maniputate shape into 3D model
 - 5) could also code an animation with python 
  + scale it, make some collisions 
- Networking: a server in python that's going to handle the database for your VR game 
 + if you have a subscription in your VR game of users and a database 
 + from the V Rprogram you would talk to the server and make sure you have all the rights then modify (librarian) 
 + python is well adapted for servers and apis 
 + for network games, python could be well adapted, especially for games that have a python codebase already 
- Machine Learning: 
 + python is a default (cannonical language) 
 + machine learning learning libraries are in python 
 + all these machine learning tool boxes are written in C++ for performance and do their calculation on the gpu for hardware acceleration (using the GPU for rendering on screen). 
 - In VR the calculations you do are GPU compatable (CPU is more polyvalent but doesn't allow for the specifics)
 - data mining from python, we're going to call the c++ tool box functions from the python code (this allows for performant code with the succintness of python and the perforance of C++). 

This allows you do big data and data mining. You need to store these in data bases. An API for your VR app allows you to handle the database for you and do big data analytics at the same time. 

** C#
This is a Microsoft language. Among its most beneficial characteristics is its portability. Regardless of whether the programmer is using Linux, Mac, or Windows, the C# syntax remains consistent. This is also an oriented programming language that's compatible with a .net backend. If the goal of your XR build is to integrate with your existing internal software solutions hosted on a .net, C# may be the most appropriate language for this work. 

Benefits of C#
- Microsoft language 
- portable language (don't need to recompile it. Virtual machine allows u to use the smae code on linux, mac, and windows 
- Oriented programming language 
- haskal (non-oriented programming language) 
- C# works with a .net backend. 
- .net: microsoft technology for making programs on windows (allowing you to span across languages) 

** C++ 
- Raw performance 
- object oriented language that's performent 

** Web GL
Web GL is a way of displaying immersive content through a web browser. This drastically expands the XR user base, as anywhere in the world - whether on their laptop, smartphone or tablet - users can access immersive media. It's available to anyone with an internet connection. As high-end VR headsets have only reached about 15 million homes today, deploying content through Web GL bridges a massive accessibility gap.

There are downsides to Web GL. For instance, it will generate a lower quality imagine than one from a game engine (engines like Unity are capable of hosting high polygon counts). In order to program physical properties into a Virtual environment built with web gl, the development team must work with a Java Script framework (Called THREE.js), affording access to ertain C++ functions. Because it's the web browser that allows this access, the process must pass through a security "sandbox." These are all elements of the world build that are available within high powered game engines. Inclusion of the aforementioned extensions saps speed and performance. 

If maximum accessibility is the most important aspect of your XR build, we'll advise Web GL. In most other cases, it's wises to build in a game engine.

... 

- Open GL is a used to show VR into a headset
A way to display 3D inside the browser and allow to forward it into a VR headset. Allows you to make 3D applications distributable on the web. You can reach anyone who has the internet. You have 2D for free. 

As a result of peformance hit is to put less detail (polygons). You might want to reduce the number of polygons 

*** Cons 
not performent: 3D has to be less detailed (polygons). Opposite of C++. 
- this is a good application for massive distribution 
- viewable on a phone, headset...for free (this is massive) 
- For high performance you go with Unity 
- You still need to integrate your 3D models from game engines
- No physics engine nor view engine 
- Java script frame work. THREE.js (allows you to make 3D programs (a bit of physics, gravity, locations, lighting). Game engine for web gl without user interface 
- this might be convenient as web gl is written in java script and can integrate with your current back/front end in JS
- with JS you're going to call some C++ functions. It's the web browser that gives you access to these elements 
 + because you're accessing them through JS, you have to go through a security (sandbox). 
 + This saps a bit of perofrmance because it needs to go through a sandbox (still using C++ under the hood) 

** Game Engine 
Game engines are a coders paradise. They provide the most dynamic combination of programming capabilities. On a foundational level, a game engine is a virtual space for working with 3D models. Think of it like the set of a movie production and consider the coders as the director of the scenes. They determine where to place the camera, the physical laws by which the room will abide, and afford full agency through the use of controllers.

***

- Game engine allows yo to set up a scene for your application (gives you virtual space where you can work with 3D models) 
- Allows you to set u a camera (perspective from which you're going to see 3D models
- Allows you to handle the controllers 
- Allows you to add physics into your scene (relies on physics engine for this)
- Game engine ties everything together 
 - physics engine 
 - lighting 
 - 3d models 
 - cameras 
- Allows you in a high level package to use low level specific packages in a dynamic VR experience 

+ unreal is performant and a bit harder to use than unity (generally used by bigger teams of developers 
+ Unity: smaller teams of developer

** Prototyping 
- Ideate 
- 1) Designing basic Assets 
 + design sensitiviies 
- 2) View assets in VR by importing through a game engine 
- 3) Defining the physics (action) 
- 4) interactivity of the objects 
 + if you want to button click to have some functionality, it's not going to happen at the prototyping level becaus it's unecessary because the guys prorgramming it know how it's going to work on the backend. 
- 5) Try to build everything that might be a constraint. What are the hardest things to do? these are the things that we'll test in the prototype (it may include reduced specifications). Prototyping is analyzing the surface area of the application and determine whether all the features are possible at the current time and budget. 
- With the real program. We'll clearn code, unit test codde, make sure assets are proper, assets are aestheitc, it's to scale, small details. 

Prototype is to prove the final project is possible. We should be able to know with the prototype whether we'll be able to run into performance issues. We'll develop an awareness of the final application. If it begins have performance issues at the prototyping level, we understand how and where to  modify the project. It doesn't necessarily follow common coding practice. Obey the spec.  

** Java Script 
language used for web xr 


** AI
***  VR analytics 
 + tourism: 
- With Big Data: you could do a heat map to know where people looked when they were inside a particular VR world
- "It's these 3D objects they looked at the most"

*** Machine learning 
- analytics requires this 

*** vR assistants 
- VR chatboxes 
 + personalized chatbox for vocal instructions for leading ppl through the world 
 + if you want to have a competition for creation of your next architecture: 
  - instead of having a person who guides you through the space, we could have AI assistants. A chatbot cannot point to something. If it's in AI or AR, chatbot could 
  - we use AI to orient people in 3D space with VR 

** TB Research Prices associated with AI features in VR 
** TB Research Spatial OS functionalities 
