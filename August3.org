** Physics Engine 

- Python we can script blender 

- physics engine: model some sort of physical interaction 
 + can modify the physics so the world does not have to abide by laws of physics: light, rain, etc. 
 + movement and logic added to their models. 

- Difference between blender and game engine: model 3D volumes, give them skeleton. Port them into game enigne. This allows you to put physics on these volumes. 
 + Football player volume: this volume has x weight and it is allowed to jump y height. 
 + Blender does not have this sense of weight or colision 
 + you should not be able to go through the walls 
 + Camera should recognize where the wall is and you can't go through the wall 

PHysics engine allows you to create parameters. 

- Wall example defiens physicsl parameters of space
- phsical parameters of a moving objects 
 + gravity is taken into account 
 + as a VR programmer you say this object weights X and has Y ability (classical physics 

- physics engine to define gravity and mass, you can allow for collisions and gravitational pull 

 + momentum is also defined 
 + magnetism needs to be added to the objects 
 + gravity 

physical laws relative to electromagnetism: electricity

relativistic mechanics: gravity

classical mechanics
 + mechanics: related to newton's laws: 1) action/reaction,  

...

** Python 
 - Python is a succinct language. 
- Object oriented programming 
- Not used in VR bcause it's not performant enough 
- Used heavily in 
 - 1) 3D modelers: Blender allows you to script using python 
 - 2) Allows you to code a shape by coding with python on Blender 
 - 3) Generate the shape
 - 4) maniputate shape into 3D model
 - 5) could also code an animation with python 
  + scale it, make some collisions 
- Networking: a server in python that's going to handle the database for your VR game 
 + if you have a subscription in your VR game of users and a database 
 + from the V Rprogram you would talk to the server and make sure you have all the rights then modify (librarian) 
 + python is well adapted for servers and apis 
 + for network games, python could be well adapted, especially for games that have a python codebase already 
- Machine Learning: 
 + python is a default (cannonical language) 
 + machine learning learning libraries are in python 
 + all these machine learning tool boxes are written in C++ for performance and do their calculation on the gpu for hardware acceleration (using the GPU for rendering on screen). 
 - In VR the calculations you do are GPU compatable (CPU is more polyvalent but doesn't allow for the specifics)
 - data mining from python, we're going to call the c++ tool box functions from the python code (this allows for performant code with the succintness of python and the perforance of C++). 

This allows you do big data and data mining. You need to store these in data bases. An API for your VR app allows you to handle the database for you and do big data analytics at the same time. Python is not so applicable to direct vr creation but it enables functionalities that VR wants in order to reach maximum performance 

** C#

Benefits of C#
- Microsoft language 
- portable language (don't need to recompile it. Virtual machine allows u to use the smae code on linux, mac, and windows 
- Oriented programming language 
- haskal (non-oriented programming language) 
- C# works with a .net backend. 
- .net: microsoft technology for making programs on windows (allowing you to span across languages) 

** C++ 
- Raw performance 
- object oriented language that's performent 

** Web GL
- Open GL is a used to show VR into a headset
A way to display 3D inside the browser and allow to forward it into a VR headset. Allows you to make 3D applications distributable on the web. You can reach anyone who has the internet. You have 2D for free. 

As a result of peformance hit is to put less detail (polygons). You might want to reduce the number of polygons 

*** Cons 
not performent: 3D has to be less detailed (polygons). Opposite of C++. 
- this is a good application for massive distribution 
- viewable on a phone, headset...for free (this is massive) 
- For high performance you go with Unity 
- You still need to integrate your 3D models from game engines
- No physics engine nor view engine 
- Java script frame work. THREE.js (allows you to make 3D programs (a bit of physics, gravity, locations, lighting). Game engine for web gl without user interface 
- this might be convenient as web gl is written in java script and can integrate with your current back/front end in JS
- with JS you're going to call some C++ functions. It's the web browser that gives you access to these elements 
 + because you're accessing them through JS, you have to go through a security (sandbox). 
 + This saps a bit of perofrmance because it needs to go through a sandbox (still using C++ under the hood) 

** Game Engine 
- Game engine allows yo to set up a scene for your application (gives you virtual space where you can work with 3D models) 
- Allows you to set u a camera (perspective from which you're going to see 3D models
- Allows you to handle the controllers 
- Allows you to add physics into your scene (relies on physics engine for this)
- Game engine ties everything together 
 - physics engine 
 - lighting 
 - 3d models 
 - cameras 
- Allows you in a high level package to use low level specific packages in a dynamic VR experience 

+ unreal is performant and a bit harder to use than unity (generally used by bigger teams of developers 
+ Unity: smaller teams of developers

*** Unreal
Historically targeting experienced develoopers. that said, they've recently released visual tools allowing designers to work in the game engine without using a single line of code. 

** Prototyping 
- Ideate 
- 1) Designing basic Assets 
 + design sensitiviies 
- 2) View assets in VR by importing through a game engine 
- 3) Defining the physics (action) 
- 4) interactivity of the objects 
 + if you want to button click to have some functionality, it's not going to happen at the prototyping level becaus it's unecessary because the guys prorgramming it know how it's going to work on the backend. 
- 5) Try to build everything that might be a constraint. What are the hardest things to do? these are the things that we'll test in the prototype (it may include reduced specifications). Prototyping is analyzing the surface area of the application and determine whether all the features are possible at the current time and budget. 
- With the real program. We'll clearn code, unit test codde, make sure assets are proper, assets are aestheitc, it's to scale, small details. 

Prototype is to prove the final project is possible. We should be able to know with the prototype whether we'll be able to run into performance issues. We'll develop an awareness of the final application. If it begins have performance issues at the prototyping level, we understand how and where to  modify the project. It doesn't necessarily follow common coding practice. Obey the spec.  

** Java Script 
language used for web xr 


** AI
***  VR analytics 
 + tourism: 
- With Big Data: you could do a heat map to know where people looked when they were inside a particular VR world
- "It's these 3D objects they looked at the most"

*** Machine learning 
- analytics requires this 

*** vR assistants 
- VR chatboxes 
 + personalized chatbox for vocal instructions for leading ppl through the world 
 + if you want to have a competition for creation of your next architecture: 
  - instead of having a person who guides you through the space, we could have AI assistants. A chatbot cannot point to something. If it's in AI or AR, chatbot could 
  - we use AI to orient people in 3D space with VR 

** TB Research Prices associated with AI features in VR 
** TB Research Spatial OS functionalities 
